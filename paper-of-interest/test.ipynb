{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'CountRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7d91049fdf63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mCountRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResnet50FPN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScales\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMincountLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPerturbationLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'CountRegressor'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "Test code written by Viresh Ranjan\n",
    "\n",
    "Last modified by: Minh Hoai Nguyen (minhhoai@cs.stonybrook.edu)\n",
    "Date: 2021/04/19\n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "import CountRegressor, Resnet50FPN\n",
    "from utils import MAPS, Scales, Transform, extract_features\n",
    "from utils import MincountLoss, PerturbationLoss\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import exists\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Few Shot Counting Evaluation code\")\n",
    "parser.add_argument(\"-dp\", \"--data_path\", type=str, default='./data/', help=\"Path to the FSC147 dataset\")\n",
    "parser.add_argument(\"-ts\", \"--test_split\", type=str, default='val', choices=[\"val_PartA\",\"val_PartB\",\"test_PartA\",\"test_PartB\",\"test\", \"val\"], help=\"what data split to evaluate on\")\n",
    "parser.add_argument(\"-m\",  \"--model_path\", type=str, default=\"./data/pretrainedModels/FamNet_Save1.pth\", help=\"path to trained model\")\n",
    "parser.add_argument(\"-a\",  \"--adapt\", action='store_true', help=\"If specified, perform test time adaptation\")\n",
    "parser.add_argument(\"-gs\", \"--gradient_steps\", type=int,default=100, help=\"number of gradient steps for the adaptation\")\n",
    "parser.add_argument(\"-lr\", \"--learning_rate\", type=float,default=1e-7, help=\"learning rate for adaptation\")\n",
    "parser.add_argument(\"-wm\", \"--weight_mincount\", type=float,default=1e-9, help=\"weight multiplier for Mincount Loss\")\n",
    "parser.add_argument(\"-wp\", \"--weight_perturbation\", type=float,default=1e-4, help=\"weight multiplier for Perturbation Loss\")\n",
    "parser.add_argument(\"-g\",  \"--gpu-id\", type=int, default=0, help=\"GPU id. Default 0 for the first GPU. Use -1 for CPU.\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_path = args.data_path\n",
    "anno_file = data_path + 'annotation_FSC147_384.json'\n",
    "data_split_file = data_path + 'Train_Test_Val_FSC_147.json'\n",
    "im_dir = data_path + 'images_384_VarV2'\n",
    "\n",
    "if not exists(anno_file) or not exists(im_dir):\n",
    "    print(\"Make sure you set up the --data-path correctly.\")\n",
    "    print(\"Current setting is {}, but the image dir and annotation file do not exist.\".format(args.data_path))\n",
    "    print(\"Aborting the evaluation\")\n",
    "    exit(-1)\n",
    "\n",
    "if not torch.cuda.is_available() or args.gpu_id < 0:\n",
    "    use_gpu = False\n",
    "    print(\"===> Using CPU mode.\")\n",
    "else:\n",
    "    use_gpu = True\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "\n",
    "resnet50_conv = Resnet50FPN()\n",
    "if use_gpu: resnet50_conv.cuda()\n",
    "resnet50_conv.eval()\n",
    "\n",
    "regressor = CountRegressor(6, pool='mean')\n",
    "regressor.load_state_dict(torch.load(args.model_path))\n",
    "if use_gpu: regressor.cuda()\n",
    "regressor.eval()\n",
    "\n",
    "with open(anno_file) as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "with open(data_split_file) as f:\n",
    "    data_split = json.load(f)\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "SAE = 0  # sum of absolute errors\n",
    "SSE = 0  # sum of square errors\n",
    "\n",
    "print(\"Evaluation on {} data\".format(args.test_split))\n",
    "im_ids = data_split[args.test_split]\n",
    "pbar = tqdm(im_ids)\n",
    "for im_id in pbar:\n",
    "    anno = annotations[im_id]\n",
    "    bboxes = anno['box_examples_coordinates']\n",
    "    dots = np.array(anno['points'])\n",
    "\n",
    "    rects = list()\n",
    "    for bbox in bboxes:\n",
    "        x1, y1 = bbox[0][0], bbox[0][1]\n",
    "        x2, y2 = bbox[2][0], bbox[2][1]\n",
    "        rects.append([y1, x1, y2, x2])\n",
    "\n",
    "    image = Image.open('{}/{}'.format(im_dir, im_id))\n",
    "    image.load()\n",
    "    sample = {'image': image, 'lines_boxes': rects}\n",
    "    sample = Transform(sample)\n",
    "    image, boxes = sample['image'], sample['boxes']\n",
    "\n",
    "    if use_gpu:\n",
    "        image = image.cuda()\n",
    "        boxes = boxes.cuda()\n",
    "\n",
    "    with torch.no_grad(): features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
    "\n",
    "    if not args.adapt:\n",
    "        with torch.no_grad(): output = regressor(features)\n",
    "    else:\n",
    "        features.required_grad = True\n",
    "        adapted_regressor = copy.deepcopy(regressor)\n",
    "        adapted_regressor.train()\n",
    "        optimizer = optim.Adam(adapted_regressor.parameters(), lr=args.learning_rate)\n",
    "        for step in range(0, args.gradient_steps):\n",
    "            optimizer.zero_grad()\n",
    "            output = adapted_regressor(features)\n",
    "            lCount = args.weight_mincount * MincountLoss(output, boxes)\n",
    "            lPerturbation = args.weight_perturbation * PerturbationLoss(output, boxes, sigma=8)\n",
    "            Loss = lCount + lPerturbation\n",
    "            # loss can become zero in some cases, where loss is a 0 valued scalar and not a tensor\n",
    "            # So Perform gradient descent only for non zero cases\n",
    "            if torch.is_tensor(Loss):\n",
    "                Loss.backward()\n",
    "                optimizer.step()\n",
    "        features.required_grad = False\n",
    "        output = adapted_regressor(features)\n",
    "\n",
    "    gt_cnt = dots.shape[0]\n",
    "    pred_cnt = output.sum().item()\n",
    "    cnt = cnt + 1\n",
    "    err = abs(gt_cnt - pred_cnt)\n",
    "    SAE += err\n",
    "    SSE += err**2\n",
    "\n",
    "\n",
    "    pbar.set_description('{:<8}: actual-predicted: {:6d}, {:6.1f}, error: {:6.1f}. Current MAE: {:5.2f}, RMSE: {:5.2f}'.\\\n",
    "                         format(im_id, gt_cnt, pred_cnt, abs(pred_cnt - gt_cnt), SAE/cnt, (SSE/cnt)**0.5))\n",
    "    print(\"\")\n",
    "\n",
    "print('On {} data, MAE: {:6.2f}, RMSE: {:6.2f}'.format(args.test_split, SAE/cnt, (SSE/cnt)**0.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
