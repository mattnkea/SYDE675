{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training Code for Learning To Count Everything, CVPR 2021\n",
    "Authors: Viresh Ranjan,Udbhav, Thu Nguyen, Minh Hoai\n",
    "\n",
    "Last modified by: Minh Hoai Nguyen (minhhoai@cs.stonybrook.edu)\n",
    "Date: 2021/04/19\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "from model import  Resnet50FPN,CountRegressor,weights_normal_init\n",
    "from utils import MAPS, Scales, Transform,TransformTrain,extract_features, visualize_output_and_save\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import exists,join\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Few Shot Counting Evaluation code\")\n",
    "parser.add_argument(\"-dp\", \"--data_path\", type=str, default='/home/hoai/DataSets/AgnosticCounting/FSC147_384_V2/', help=\"Path to the FSC147 dataset\")\n",
    "parser.add_argument(\"-o\", \"--output_dir\", type=str,default=\"./logsSave\", help=\"/Path/to/output/logs/\")\n",
    "parser.add_argument(\"-ts\", \"--test-split\", type=str, default='val', choices=[\"train\", \"test\", \"val\"], help=\"what data split to evaluate on on\")\n",
    "parser.add_argument(\"-ep\", \"--epochs\", type=int,default=1500, help=\"number of training epochs\")\n",
    "parser.add_argument(\"-g\", \"--gpu\", type=int,default=0, help=\"GPU id\")\n",
    "parser.add_argument(\"-lr\", \"--learning-rate\", type=float,default=1e-5, help=\"learning rate\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "data_path = args.data_path\n",
    "anno_file = data_path + 'annotation_FSC147_384.json'\n",
    "data_split_file = data_path + 'Train_Test_Val_FSC_147.json'\n",
    "im_dir = data_path + 'images_384_VarV2'\n",
    "gt_dir = data_path + 'gt_density_map_adaptive_384_VarV2'\n",
    "\n",
    "if not exists(args.output_dir):\n",
    "    os.mkdir(args.output_dir)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "\n",
    "criterion = nn.MSELoss().cuda()\n",
    "\n",
    "resnet50_conv = Resnet50FPN()\n",
    "resnet50_conv.cuda()\n",
    "resnet50_conv.eval()\n",
    "\n",
    "regressor = CountRegressor(6, pool='mean')\n",
    "weights_normal_init(regressor, dev=0.001)\n",
    "regressor.train()\n",
    "regressor.cuda()\n",
    "optimizer = optim.Adam(regressor.parameters(), lr = args.learning_rate)\n",
    "\n",
    "with open(anno_file) as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "with open(data_split_file) as f:\n",
    "    data_split = json.load(f)\n",
    "\n",
    "def train():\n",
    "    print(\"Training on FSC147 train set data\")\n",
    "    im_ids = data_split['train']\n",
    "    random.shuffle(im_ids)\n",
    "    train_mae = 0\n",
    "    train_rmse = 0\n",
    "    train_loss = 0\n",
    "    pbar = tqdm(im_ids)\n",
    "    cnt = 0\n",
    "    for im_id in pbar:\n",
    "        cnt += 1\n",
    "        anno = annotations[im_id]\n",
    "        bboxes = anno['box_examples_coordinates']\n",
    "        dots = np.array(anno['points'])\n",
    "\n",
    "        rects = list()\n",
    "        for bbox in bboxes:\n",
    "            x1 = bbox[0][0]\n",
    "            y1 = bbox[0][1]\n",
    "            x2 = bbox[2][0]\n",
    "            y2 = bbox[2][1]\n",
    "            rects.append([y1, x1, y2, x2])\n",
    "\n",
    "        image = Image.open('{}/{}'.format(im_dir, im_id))\n",
    "        image.load()\n",
    "        density_path = gt_dir + '/' + im_id.split(\".jpg\")[0] + \".npy\"\n",
    "        density = np.load(density_path).astype('float32')    \n",
    "        sample = {'image':image,'lines_boxes':rects,'gt_density':density}\n",
    "        sample = TransformTrain(sample)\n",
    "        image, boxes,gt_density = sample['image'].cuda(), sample['boxes'].cuda(),sample['gt_density'].cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
    "        features.requires_grad = True\n",
    "        optimizer.zero_grad()\n",
    "        output = regressor(features)\n",
    "\n",
    "        #if image size isn't divisible by 8, gt size is slightly different from output size\n",
    "        if output.shape[2] != gt_density.shape[2] or output.shape[3] != gt_density.shape[3]:\n",
    "            orig_count = gt_density.sum().detach().item()\n",
    "            gt_density = F.interpolate(gt_density, size=(output.shape[2],output.shape[3]),mode='bilinear')\n",
    "            new_count = gt_density.sum().detach().item()\n",
    "            if new_count > 0: gt_density = gt_density * (orig_count / new_count)\n",
    "        loss = criterion(output, gt_density)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred_cnt = torch.sum(output).item()\n",
    "        gt_cnt = torch.sum(gt_density).item()\n",
    "        cnt_err = abs(pred_cnt - gt_cnt)\n",
    "        train_mae += cnt_err\n",
    "        train_rmse += cnt_err ** 2\n",
    "        pbar.set_description('actual-predicted: {:6.1f}, {:6.1f}, error: {:6.1f}. Current MAE: {:5.2f}, RMSE: {:5.2f} Best VAL MAE: {:5.2f}, RMSE: {:5.2f}'.format( gt_cnt, pred_cnt, abs(pred_cnt - gt_cnt), train_mae/cnt, (train_rmse/cnt)**0.5,best_mae,best_rmse))\n",
    "        print(\"\")\n",
    "    train_loss = train_loss / len(im_ids)\n",
    "    train_mae = (train_mae / len(im_ids))\n",
    "    train_rmse = (train_rmse / len(im_ids))**0.5\n",
    "    return train_loss,train_mae,train_rmse\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "def eval():\n",
    "    cnt = 0\n",
    "    SAE = 0 # sum of absolute errors\n",
    "    SSE = 0 # sum of square errors\n",
    "\n",
    "    print(\"Evaluation on {} data\".format(args.test_split))\n",
    "    im_ids = data_split[args.test_split]\n",
    "    pbar = tqdm(im_ids)\n",
    "    for im_id in pbar:\n",
    "        anno = annotations[im_id]\n",
    "        bboxes = anno['box_examples_coordinates']\n",
    "        dots = np.array(anno['points'])\n",
    "\n",
    "        rects = list()\n",
    "        for bbox in bboxes:\n",
    "            x1 = bbox[0][0]\n",
    "            y1 = bbox[0][1]\n",
    "            x2 = bbox[2][0]\n",
    "            y2 = bbox[2][1]\n",
    "            rects.append([y1, x1, y2, x2])\n",
    "\n",
    "        image = Image.open('{}/{}'.format(im_dir, im_id))\n",
    "        image.load()\n",
    "        sample = {'image':image,'lines_boxes':rects}\n",
    "        sample = Transform(sample)\n",
    "        image, boxes = sample['image'].cuda(), sample['boxes'].cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = regressor(extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales))\n",
    "\n",
    "        gt_cnt = dots.shape[0]\n",
    "        pred_cnt = output.sum().item()\n",
    "        cnt = cnt + 1\n",
    "        err = abs(gt_cnt - pred_cnt)\n",
    "        SAE += err\n",
    "        SSE += err**2\n",
    "\n",
    "        pbar.set_description('{:<8}: actual-predicted: {:6d}, {:6.1f}, error: {:6.1f}. Current MAE: {:5.2f}, RMSE: {:5.2f}'.format(im_id, gt_cnt, pred_cnt, abs(pred_cnt - gt_cnt), SAE/cnt, (SSE/cnt)**0.5))\n",
    "        print(\"\")\n",
    "\n",
    "    print('On {} data, MAE: {:6.2f}, RMSE: {:6.2f}'.format(args.test_split, SAE/cnt, (SSE/cnt)**0.5))\n",
    "    return SAE/cnt, (SSE/cnt)**0.5\n",
    "\n",
    "\n",
    "best_mae, best_rmse = 1e7, 1e7\n",
    "stats = list()\n",
    "for epoch in range(0,args.epochs):\n",
    "    regressor.train()\n",
    "    train_loss,train_mae,train_rmse = train()\n",
    "    regressor.eval()\n",
    "    val_mae,val_rmse = eval()\n",
    "    stats.append((train_loss, train_mae, train_rmse, val_mae, val_rmse))\n",
    "    stats_file = join(args.output_dir, \"stats\" +  \".txt\")\n",
    "    with open(stats_file, 'w') as f:\n",
    "        for s in stats:\n",
    "            f.write(\"%s\\n\" % ','.join([str(x) for x in s]))    \n",
    "    if best_mae >= val_mae:\n",
    "        best_mae = val_mae\n",
    "        best_rmse = val_rmse\n",
    "        model_name = args.output_dir + '/' + \"FamNet.pth\"\n",
    "        torch.save(regressor.state_dict(), model_name)\n",
    "\n",
    "    print(\"Epoch {}, Avg. Epoch Loss: {} Train MAE: {} Train RMSE: {} Val MAE: {} Val RMSE: {} Best Val MAE: {} Best Val RMSE: {} \".format(\n",
    "              epoch+1,  stats[-1][0], stats[-1][1], stats[-1][2], stats[-1][3], stats[-1][4], best_mae, best_rmse))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
